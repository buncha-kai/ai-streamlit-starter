import io
import joblib
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

from sklearn import datasets, metrics, model_selection
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

st.set_page_config(
    page_title="AI Starter (Streamlit + scikit-learn)",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ AI Starter: Classification ‡∏î‡πâ‡∏ß‡∏¢ Streamlit + scikit-learn")
st.caption("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå AI ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô: ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡πÅ‡∏ö‡πà‡∏á train/test ‚Üí ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Üí ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• ‚Üí ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà")

# ------------------------------
# Utilities
# ------------------------------
@st.cache_data
def load_iris_df():
    iris = datasets.load_iris(as_frame=True)
    df = iris.frame.copy()
    df.rename(columns={
        "sepal length (cm)": "sepal_length",
        "sepal width (cm)": "sepal_width",
        "petal length (cm)": "petal_length",
        "petal width (cm)": "petal_width",
        "target": "species"
    }, inplace=True)
    target_names = iris.target_names
    return df, target_names

def build_model(model_name, params):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô: StandardScaler (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô RF) + Model"""
    if model_name == "Logistic Regression":
        pipe = Pipeline([
            ("scaler", StandardScaler()),
            ("clf", LogisticRegression(
                C=params.get("C", 1.0),
                max_iter=1000,
                random_state=42
            ))
        ])
    elif model_name == "KNN":
        pipe = Pipeline([
            ("scaler", StandardScaler()),
            ("clf", KNeighborsClassifier(
                n_neighbors=params.get("n_neighbors", 5),
                weights=params.get("weights", "uniform")
            ))
        ])
    elif model_name == "SVM (RBF)":
        pipe = Pipeline([
            ("scaler", StandardScaler()),
            ("clf", SVC(
                C=params.get("C", 1.0),
                gamma=params.get("gamma", "scale"),
                probability=True,
                random_state=42
            ))
        ])
    elif model_name == "Random Forest":
        # RF ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πÄ‡∏Å‡∏•
        pipe = Pipeline([
            ("clf", RandomForestClassifier(
                n_estimators=params.get("n_estimators", 200),
                max_depth=params.get("max_depth", None),
                random_state=42
            ))
        ])
    else:
        raise ValueError("‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    return pipe

def plot_confusion_matrix(cm, classes):
    fig, ax = plt.subplots(figsize=(4.5, 4.5))
    im = ax.imshow(cm, interpolation='nearest')
    ax.figure.colorbar(im, ax=ax)
    ax.set(
        xticks=np.arange(cm.shape[1]),
        yticks=np.arange(cm.shape[0]),
        xticklabels=classes,
        yticklabels=classes,
        ylabel='True label',
        xlabel='Predicted label',
        title='Confusion Matrix'
    )
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")

    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], 'd'),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return fig

# ------------------------------
# Sidebar Controls
# ------------------------------
st.sidebar.header("‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• & ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô")

model_name = st.sidebar.selectbox(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•",
    ["Logistic Regression", "KNN", "SVM (RBF)", "Random Forest"]
)

test_size = st.sidebar.slider("‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô Test size", 0.1, 0.5, 0.2, 0.05)
shuffle_data = st.sidebar.checkbox("‡∏™‡∏•‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Shuffle)", True)
random_state = st.sidebar.number_input("Random state", value=42, step=1)

st.sidebar.subheader("Hyperparameters")
params = {}
if model_name == "Logistic Regression":
    params["C"] = st.sidebar.number_input("C (regularization)", min_value=0.01, value=1.0, step=0.1)
elif model_name == "KNN":
    params["n_neighbors"] = st.sidebar.slider("n_neighbors (k)", 1, 20, 5, 1)
    params["weights"] = st.sidebar.selectbox("weights", ["uniform", "distance"])
elif model_name == "SVM (RBF)":
    params["C"] = st.sidebar.number_input("C (regularization)", min_value=0.01, value=1.0, step=0.1)
    params["gamma"] = st.sidebar.selectbox("gamma", ["scale", "auto"])
elif model_name == "Random Forest":
    params["n_estimators"] = st.sidebar.slider("n_estimators", 50, 500, 200, 50)
    max_depth_opt = st.sidebar.selectbox("max_depth", ["None", 3, 5, 8, 12])
    params["max_depth"] = None if max_depth_opt == "None" else int(max_depth_opt)

col_left, col_right = st.columns([1.1, 1])

# ------------------------------
# Load data
# ------------------------------
df, target_names = load_iris_df()
feature_cols = ["sepal_length", "sepal_width", "petal_length", "petal_width"]
X = df[feature_cols].values
y = df["species"].values

with col_left:
    st.subheader("üëÄ ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")
    st.dataframe(df.sample(10, random_state=42), use_container_width=True)
    st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: **{len(df)}**")

# ------------------------------
# Train/Test split
# ------------------------------
X_train, X_test, y_train, y_test = model_selection.train_test_split(
    X, y, test_size=test_size, shuffle=shuffle_data, random_state=random_state, stratify=y
)

# ------------------------------
# Train Model
# ------------------------------
with col_right:
    st.subheader("üß† ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    train_btn = st.button("Train / Evaluate", type="primary", use_container_width=True)

    if train_btn:
        model = build_model(model_name, params)
        model.fit(X_train, y_train)

        # Evaluate
        y_pred = model.predict(X_test)
        acc = metrics.accuracy_score(y_test, y_pred)
        cm = metrics.confusion_matrix(y_test, y_pred)

        st.success(f"Accuracy (Test): **{acc:.4f}**")
        fig_cm = plot_confusion_matrix(cm, target_names)
        st.pyplot(fig_cm, use_container_width=True)

        # Classification report (‡∏¢‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢)
        report = metrics.classification_report(y_test, y_pred, target_names=target_names, output_dict=True)
        rep_df = pd.DataFrame(report).transpose()
        st.markdown("**Classification Report**")
        st.dataframe(rep_df.round(3), use_container_width=True)

        # Save model to bytes for download
        buffer = io.BytesIO()
        joblib.dump(model, buffer)
        buffer.seek(0)
        st.download_button(
            "üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß (.joblib)",
            data=buffer,
            file_name=f"iris_{model_name.replace(' ', '_').lower()}_model.joblib",
            mime="application/octet-stream",
            use_container_width=True
        )

# ------------------------------
# Predict on user data
# ------------------------------
st.markdown("---")
st.subheader("üîÆ ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (CSV)")

st.markdown(
    """
- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: `sepal_length, sepal_width, petal_length, petal_width`  
- ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡πÇ‡∏°‡πà)
"""
)

uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV", type=["csv"])
if uploaded is not None:
    try:
        user_df = pd.read_csv(uploaded)
        missing = [c for c in feature_cols if c not in user_df.columns]
        if missing:
            st.error(f"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏≤‡∏¢‡πÑ‡∏õ: {missing}")
        else:
            st.write("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î:")
            st.dataframe(user_df.head(), use_container_width=True)

            # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô)
            model_for_pred = build_model(model_name, params)
            model_for_pred.fit(X, y)

            preds = model_for_pred.predict(user_df[feature_cols].values)
            pred_names = [target_names[i] if isinstance(i, (int, np.integer)) else target_names[int(i)] for i in preds]
            out = user_df.copy()
            out["predicted_species"] = pred_names

            st.success("‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‚úÖ")
            st.dataframe(out.head(20), use_container_width=True)

            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            csv_bytes = out.to_csv(index=False).encode("utf-8")
            st.download_button(
                "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå (CSV)",
                data=csv_bytes,
                file_name="predictions.csv",
                mime="text/csv"
            )
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå/‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå: {e}")

# ------------------------------
# How it works
# ------------------------------
with st.expander("‚ÑπÔ∏è ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)"):
    st.markdown("""
1) **‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Iris**: ‡∏°‡∏µ 4 ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå (sepal_length, sepal_width, petal_length, petal_width) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™ 3 ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏î‡∏≠‡∏Å‡πÑ‡∏°‡πâ  
2) **‡πÅ‡∏ö‡πà‡∏á Train/Test**: ‡πÉ‡∏ä‡πâ `train_test_split` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô  
3) **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Hyperparameters ‡πÉ‡∏ô Sidebar  
   - Logistic Regression / KNN / SVM / Random Forest  
   - ‡πÉ‡∏ä‡πâ `Pipeline` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏° `StandardScaler` ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏à‡∏≥‡πÅ‡∏ô‡∏Å (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô RF)  
4) **‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô**: ‡πÅ‡∏™‡∏î‡∏á Accuracy, Confusion Matrix ‡πÅ‡∏•‡∏∞ Classification Report  
5) **‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà**: ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î CSV ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 4 ‡∏ï‡∏±‡∏ß ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå  
""")
